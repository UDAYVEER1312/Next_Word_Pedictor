{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5a28c4a5-7df4-4585-a703-d25ab79e2c99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5a28c4a5-7df4-4585-a703-d25ab79e2c99",
        "outputId": "0b4f5726-401f-4429-a888-a5951a7b3907"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.9.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b3db6469-744a-4d8c-8342-9a060bba2e13",
      "metadata": {
        "id": "b3db6469-744a-4d8c-8342-9a060bba2e13"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3cdc93fb-119d-4f10-9785-e989570df957",
      "metadata": {
        "scrolled": true,
        "id": "3cdc93fb-119d-4f10-9785-e989570df957"
      },
      "outputs": [],
      "source": [
        "# fetching the data :\n",
        "data = open('general_speak.txt','r').read()\n",
        "data = data.replace('\\\\n','')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdUQaGmGTj_f",
        "outputId": "6705d16d-070c-488b-be6d-01b4eec8c741"
      },
      "id": "OdUQaGmGTj_f",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RmpsvMqtTi5x"
      },
      "id": "RmpsvMqtTi5x"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fb66b5ed-c685-4cc5-ae82-83e7551c77ea",
      "metadata": {
        "scrolled": true,
        "id": "fb66b5ed-c685-4cc5-ae82-83e7551c77ea"
      },
      "outputs": [],
      "source": [
        "# tokenizing the data using nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(data.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d4e136a5-25a1-47ea-a770-2ebdbbcc16a2",
      "metadata": {
        "scrolled": true,
        "id": "d4e136a5-25a1-47ea-a770-2ebdbbcc16a2"
      },
      "outputs": [],
      "source": [
        "# creating vocabulary :\n",
        "from collections import Counter\n",
        "vocab = {'<UNK>':0}\n",
        "count = Counter(tokens) # creates a dictionary , removes repeates tokens\n",
        "for token in count.keys():\n",
        "    vocab[token] = len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "79face67-4a4c-4172-b2a8-22dfad935ed1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79face67-4a4c-4172-b2a8-22dfad935ed1",
        "outputId": "5056fe18-c115-4973-8cd6-e28be277c027"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1889, 1888)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(vocab), len(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c0546227-cb3e-4f57-96a8-f3701dc6f804",
      "metadata": {
        "id": "c0546227-cb3e-4f57-96a8-f3701dc6f804"
      },
      "outputs": [],
      "source": [
        "# fetching all sentences in the data :\n",
        "sentences = data.split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "53094454-f8d3-45f0-a237-9a2846eb543c",
      "metadata": {
        "id": "53094454-f8d3-45f0-a237-9a2846eb543c"
      },
      "outputs": [],
      "source": [
        "# text -> tokens -> indices\n",
        "def token_to_index(token:str,vocab):\n",
        "    return [vocab[t] if t in vocab else vocab['<UNK>'] for t in word_tokenize(token.lower())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "aa28456b-7c30-496f-9b65-4c53cd2a57d4",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa28456b-7c30-496f-9b65-4c53cd2a57d4",
        "outputId": "f91997c6-6ff0-4050-e5cd-9b4010f1710c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 1, 13, 14]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# tokenizing sentences :\n",
        "tokenized_sentences = []\n",
        "for sentence in sentences:\n",
        "    tokenized_sentences.append(token_to_index(sentence,vocab))\n",
        "tokenized_sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "edab1c3c-5a64-4c92-995a-b18e40c2b3bb",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edab1c3c-5a64-4c92-995a-b18e40c2b3bb",
        "outputId": "fcfee60d-1425-4003-835e-c4cd0d2e52ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The sun sets slowly behind the mountain, casting a warm glow over the valley.',\n",
              " [1, 2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 1, 13, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "sentences[0],tokenized_sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f7b6b6b1-146a-4054-ae58-db5ed035b229",
      "metadata": {
        "scrolled": true,
        "id": "f7b6b6b1-146a-4054-ae58-db5ed035b229"
      },
      "outputs": [],
      "source": [
        "# generating training sequence :\n",
        "train_sequence = []\n",
        "for ts in tokenized_sentences:\n",
        "    for i in range(len(ts)):\n",
        "        train_sequence.append(ts[:i+1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "31274c75-06af-4fe6-b55c-b50f9a4b1fd0",
      "metadata": {
        "scrolled": true,
        "id": "31274c75-06af-4fe6-b55c-b50f9a4b1fd0"
      },
      "outputs": [],
      "source": [
        "# appplying padding in the beginning of each sequence in the train_sequence\n",
        "# finding the sequence with largest size :\n",
        "max_size = max(len(t) for t in train_sequence)\n",
        "for i in range(len(train_sequence)):\n",
        "    train_sequence[i] = [0 for i in range(max_size-len(train_sequence[i]))] + train_sequence[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "21f25906-3cfa-45b2-9875-0d01021584ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21f25906-3cfa-45b2-9875-0d01021584ad",
        "outputId": "f2bcb56b-f3dd-4a74-d14a-e1744d05df90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11973, 34])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([11973, 33]), torch.Size([11973]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# fetching sequence and targets :\n",
        "train_sequence = torch.tensor(train_sequence)\n",
        "print(train_sequence.shape)\n",
        "sequences , targets = train_sequence[:,:-1] , train_sequence[:,-1]\n",
        "sequences.shape, targets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "44b81c59-1c59-4ca3-a41e-59f4b01f128e",
      "metadata": {
        "id": "44b81c59-1c59-4ca3-a41e-59f4b01f128e"
      },
      "outputs": [],
      "source": [
        "# making custom dataset :\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self,sequences,targets,vocab):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "        self.vocab = vocab\n",
        "    def __len__(self):\n",
        "        return self.targets.shape[0]\n",
        "    def __getitem__(self,index):\n",
        "        return self.sequences[index] , self.targets[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "40c070e9-9e2f-4730-8b1f-c202d6d16ad3",
      "metadata": {
        "id": "40c070e9-9e2f-4730-8b1f-c202d6d16ad3"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(sequences,targets,vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f80860a0-01be-4f53-b4ae-94ddad4f2a26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f80860a0-01be-4f53-b4ae-94ddad4f2a26",
        "outputId": "f616134c-b367-483e-bd06-05d04c07c7f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11973"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e8a5105a-64a8-424b-9ec7-2e91f9071a8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8a5105a-64a8-424b-9ec7-2e91f9071a8b",
        "outputId": "9e41722b-b291-40af-99bc-7fb86d87b8c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,  20, 191, 217, 485,  30, 127,   9,\n",
              "         220, 486,  85, 487, 488]),\n",
              " tensor(19))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# (training sequence , target token)\n",
        "dataset[1001]  # show any item of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "336f9dcb-a14f-46a8-932c-93e1fbf0e5be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "336f9dcb-a14f-46a8-932c-93e1fbf0e5be",
        "outputId": "3b9a28fd-8f9f-44db-95f0-4dbe39cc78bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "375"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# creating the datatloader :\n",
        "dataloader = DataLoader(dataset = dataset, batch_size = 32, shuffle = True)\n",
        "len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3d18cd57-230c-4f06-aba8-a2123306c4e3",
      "metadata": {
        "id": "3d18cd57-230c-4f06-aba8-a2123306c4e3"
      },
      "outputs": [],
      "source": [
        "# lstm with an embedding of 150\n",
        "class lstm_model(nn.Module):\n",
        "    def __init__(self,embeddings,hidden,vocab_size):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embd = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embeddings)\n",
        "        self.lstm = nn.LSTM(input_size=embeddings, hidden_size=hidden, batch_first = True)\n",
        "        self.fully_connected = nn.Linear(in_features = hidden , out_features = vocab_size)\n",
        "    def forward(self,text):\n",
        "        x = self.embd(text)\n",
        "        hidden,final_hidden_and_cell = self.lstm(x)  # returns tuple  : (all hidden states , (final_hidden_state , final_cell_state))\n",
        "        return self.fully_connected(final_hidden_and_cell[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2c9735b6-6e00-4ae7-be04-2c6ec3c3d316",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c9735b6-6e00-4ae7-be04-2c6ec3c3d316",
        "outputId": "8ac19028-f628-4102-b641-e81a16b57351"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_model(\n",
              "  (embd): Embedding(1889, 150)\n",
              "  (lstm): LSTM(150, 250, batch_first=True)\n",
              "  (fully_connected): Linear(in_features=250, out_features=1889, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model = lstm_model(150,250,len(vocab))\n",
        "model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c100900a-1041-4cab-9a37-95a9d67720a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c100900a-1041-4cab-9a37-95a9d67720a2",
        "outputId": "748378bf-2b0e-4ef7-c13f-142358cfcd44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 33, 150])\n",
            "torch.Size([1, 33, 250]) torch.Size([1, 1, 250]) torch.Size([1, 1, 250])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 1889])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# check if all layers have expected output shapes...\n",
        "x = dataset[100][0].unsqueeze(0).to('cuda')\n",
        "x = model.embd(x)\n",
        "print(x.shape)\n",
        "hidden,final = model.lstm(x)\n",
        "print(hidden.shape,final[0].shape,final[1].shape)\n",
        "model.fully_connected(final[0]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f989f956-d81f-4d8e-a459-93d89bf18476",
      "metadata": {
        "id": "f989f956-d81f-4d8e-a459-93d89bf18476"
      },
      "outputs": [],
      "source": [
        "# initializing cross entropy loss and Adam optimizer\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "a38d7dd9-1933-4af6-9e2b-cb0a51590d45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a38d7dd9-1933-4af6-9e2b-cb0a51590d45",
        "outputId": "0f21d83e-783f-4331-a536-779cf7d47d5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 2 | train_loss : 3.0516974925994873\n",
            "Epoch : 4 | train_loss : 1.9016647338867188\n",
            "Epoch : 6 | train_loss : 1.2000373601913452\n",
            "Epoch : 8 | train_loss : 0.871799647808075\n",
            "Epoch : 10 | train_loss : 0.7572396397590637\n",
            "Epoch : 12 | train_loss : 0.7110127806663513\n",
            "Epoch : 14 | train_loss : 0.6853783130645752\n",
            "Epoch : 16 | train_loss : 0.67520672082901\n",
            "Epoch : 18 | train_loss : 0.6670853495597839\n",
            "Epoch : 20 | train_loss : 0.6646623015403748\n"
          ]
        }
      ],
      "source": [
        "# run for 20 epochs :\n",
        "epochs = 20\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    for data in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(data[0].to('cuda'))\n",
        "        # print(pred.shape)\n",
        "        # print(data[1].shape)\n",
        "        loss = loss_fun(pred.squeeze(0),data[1].squeeze(0).to('cuda'))\n",
        "        epoch_loss += loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch %2 == 1:\n",
        "        print(f'Epoch : {epoch+1} | train_loss : {epoch_loss/len(dataloader)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "472dc305-362e-4b61-aee9-4a574aaaa6c3",
      "metadata": {
        "id": "472dc305-362e-4b61-aee9-4a574aaaa6c3"
      },
      "outputs": [],
      "source": [
        "# making prediction :\n",
        "def predict(model,vocab,text):\n",
        "    # tokenize to indices :\n",
        "    tokens = token_to_index(text,vocab)\n",
        "    # add paddings :\n",
        "    padded_token_sequence = [0]*(max_size - 1 - len(tokens)) + tokens # input to the model should a vector\n",
        "\n",
        "    input_sequence = torch.tensor(padded_token_sequence)\n",
        "\n",
        "    pred = model(input_sequence.unsqueeze(0).to('cuda')).squeeze(0)\n",
        "\n",
        "    max_val , index = torch.max(pred,dim=1) # get the max prediction value and teh prediction\n",
        "    return list(vocab.keys())[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d145b314-cc07-498e-875e-17845c53faef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d145b314-cc07-498e-875e-17845c53faef",
        "outputId": "432a362a-1e42-4715-f03d-fd6cafd07a95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recycling conserves natural resources ,\n",
            "Recycling conserves natural resources , reduces\n",
            "Recycling conserves natural resources , reduces landfill\n",
            "Recycling conserves natural resources , reduces landfill waste\n",
            "Recycling conserves natural resources , reduces landfill waste ,\n",
            "Recycling conserves natural resources , reduces landfill waste , and\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers greenhouse\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers greenhouse gas\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers greenhouse gas emissions\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers greenhouse gas emissions ,\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers greenhouse gas emissions , making\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers greenhouse gas emissions , making it\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers greenhouse gas emissions , making it essential\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers greenhouse gas emissions , making it essential for\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers greenhouse gas emissions , making it essential for environmental\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers greenhouse gas emissions , making it essential for environmental sustainability\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers greenhouse gas emissions , making it essential for environmental sustainability ,\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers greenhouse gas emissions , making it essential for environmental sustainability , according\n",
            "Recycling conserves natural resources , reduces landfill waste , and lowers greenhouse gas emissions , making it essential for environmental sustainability , according to\n"
          ]
        }
      ],
      "source": [
        "# predictoin from the model in a sequence of length 20\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sequence = 20\n",
        "    input_seq = 'Recycling conserves natural resources'\n",
        "    for i in range(sequence):\n",
        "        output = predict(model,vocab,input_seq)\n",
        "        input_seq += ' '+output\n",
        "        print(input_seq)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}